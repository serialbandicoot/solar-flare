{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar-Flare\n",
    "\n",
    "This project is using TensorFlow Object detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing Tensor Flow Models \n",
    "\n",
    "The models directory, which is required by TensorFlow must be downloaded separately and is not part of this repo, due to it's size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 90359, done.\u001b[K\n",
      "remote: Counting objects: 100% (152/152), done.\u001b[K\n",
      "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
      "remote: Total 90359 (delta 79), reused 139 (delta 68), pack-reused 90207\u001b[K\n",
      "Receiving objects: 100% (90359/90359), 608.42 MiB | 2.66 MiB/s, done.\n",
      "Resolving deltas: 100% (65103/65103), done.\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/tensorflow/models.git\n",
    "#!pip install -q -r models/official/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T13:50:26.743115Z",
     "iopub.status.busy": "2024-02-15T13:50:26.742735Z",
     "iopub.status.idle": "2024-02-15T13:50:26.750379Z",
     "shell.execute_reply": "2024-02-15T13:50:26.749419Z",
     "shell.execute_reply.started": "2024-02-15T13:50:26.743085Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(f\"{os.getcwd()}/models/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-15T13:50:37.498539Z",
     "iopub.status.busy": "2024-02-15T13:50:37.498090Z",
     "iopub.status.idle": "2024-02-15T13:50:38.415037Z",
     "shell.execute_reply": "2024-02-15T13:50:38.412947Z",
     "shell.execute_reply.started": "2024-02-15T13:50:37.498497Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import pprint\n",
    "import tempfile\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from six import BytesIO\n",
    "from IPython import display\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam.treweek/BJSS/MetOffice/solar-flare/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "import orbit\n",
    "\n",
    "from official import core\n",
    "from official.core import exp_factory\n",
    "from official.core import config_definitions as cfg\n",
    "from official.vision.serving import export_saved_model_lib\n",
    "from official.vision.ops.preprocess_ops import normalize_image\n",
    "from official.vision.ops.preprocess_ops import resize_and_crop_image\n",
    "from official.vision.utils.object_detection import visualization_utils\n",
    "from official.vision.dataloaders.tf_example_decoder import TfExampleDecoder\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4) # Set Pretty Print Indentation\n",
    "print(tf.__version__) # Check the version of tensorflow used\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Formatting\n",
    "\n",
    "The labels have been generated using labelme, therefore the format for tensorflow has been converted to the COCO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export PYTHONPATH=$PYTHONPATH:/path/to/models\n",
    "python -m official.vision.data.create_coco_tf_record \\\n",
    "    --logtostderr   \\\n",
    "    --image_dir=\"./BCC.v1-bccd.coco/train\"  \\\n",
    "    --object_annotations_file=\"./BCC.v1-bccd.coco/train/_annotations.coco.json\"   \\\n",
    "    --output_file_prefix=\"./bccd_coco_tfrecords/train\"  \\\n",
    "     --num_shards=1\n",
    "\n",
    "python -m official.vision.data.create_coco_tf_record \\\n",
    "    --logtostderr   \\\n",
    "    --image_dir=\"./BCC.v1-bccd.coco/valid\"  \\\n",
    "    --object_annotations_file=\"./BCC.v1-bccd.coco/valid/_annotations.coco.json\"   \\\n",
    "    --output_file_prefix=\"./bccd_coco_tfrecords/valid\"  \\\n",
    "     --num_shards=1\n",
    "\n",
    "python -m official.vision.data.create_coco_tf_record \\\n",
    "    --logtostderr   \\\n",
    "    --image_dir=\"./BCC.v1-bccd.coco/test\"  \\\n",
    "    --object_annotations_file=\"./BCC.v1-bccd.coco/test/_annotations.coco.json\"   \\\n",
    "    --output_file_prefix=\"./bccd_coco_tfrecords/test\"  \\\n",
    "     --num_shards=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_input_path = './bccd_coco_tfrecords/train-00000-of-00001.tfrecord'\n",
    "valid_data_input_path = './bccd_coco_tfrecords/valid-00000-of-00001.tfrecord'\n",
    "test_data_input_path = './bccd_coco_tfrecords/test-00000-of-00001.tfrecord'\n",
    "model_dir = './trained_model/'\n",
    "export_dir ='./exported_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = exp_factory.get_exp_config('retinanet_resnetfpn_coco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_classes = 3\n",
    "\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "IMG_SIZE = [HEIGHT, WIDTH, 3]\n",
    "\n",
    "# Backbone config.\n",
    "exp_config.task.freeze_backbone = False\n",
    "exp_config.task.annotation_file = ''\n",
    "\n",
    "# Model config.\n",
    "exp_config.task.model.input_size = IMG_SIZE\n",
    "exp_config.task.model.num_classes = num_classes + 1\n",
    "exp_config.task.model.detection_generator.tflite_post_processing.max_classes_per_detection = exp_config.task.model.num_classes\n",
    "\n",
    "# Training data config.\n",
    "exp_config.task.train_data.input_path = train_data_input_path\n",
    "exp_config.task.train_data.dtype = 'float32'\n",
    "exp_config.task.train_data.global_batch_size = batch_size\n",
    "exp_config.task.train_data.parser.aug_scale_max = 1.0\n",
    "exp_config.task.train_data.parser.aug_scale_min = 1.0\n",
    "\n",
    "# Validation data config.\n",
    "exp_config.task.validation_data.input_path = valid_data_input_path\n",
    "exp_config.task.validation_data.dtype = 'float32'\n",
    "exp_config.task.validation_data.global_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logical_device_names = [logical_device.name for logical_device in tf.config.list_logical_devices()]\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'GPU'\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  print('This may be broken in Colab.')\n",
    "  device = 'TPU'\n",
    "else:\n",
    "  print('Running on CPU is slow, so only train for a few steps.')\n",
    "  device = 'CPU'\n",
    "\n",
    "\n",
    "train_steps = 1000\n",
    "exp_config.trainer.steps_per_loop = 100 # steps_per_loop = num_of_training_examples // train_batch_size\n",
    "\n",
    "exp_config.trainer.summary_interval = 100\n",
    "exp_config.trainer.checkpoint_interval = 100\n",
    "exp_config.trainer.validation_interval = 100\n",
    "exp_config.trainer.validation_steps =  100 # validation_steps = num_of_validation_examples // eval_batch_size\n",
    "exp_config.trainer.train_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_steps = 100\n",
    "exp_config.trainer.optimizer_config.learning_rate.type = 'cosine'\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.decay_steps = train_steps\n",
    "exp_config.trainer.optimizer_config.learning_rate.cosine.initial_learning_rate = 0.1\n",
    "exp_config.trainer.optimizer_config.warmup.linear.warmup_learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(exp_config.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_config.runtime.mixed_precision_dtype == tf.float16:\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "if 'GPU' in ''.join(logical_device_names):\n",
    "  distribution_strategy = tf.distribute.MirroredStrategy()\n",
    "elif 'TPU' in ''.join(logical_device_names):\n",
    "  tf.tpu.experimental.initialize_tpu_system()\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='/device:TPU_SYSTEM:0')\n",
    "  distribution_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "  print('Warning: this will be really slow.')\n",
    "  distribution_strategy = tf.distribute.OneDeviceStrategy(logical_device_names[0])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "  task = core.task_factory.get_task(exp_config.task, logging_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in task.build_inputs(exp_config.task.train_data).take(1):\n",
    "  print()\n",
    "  print(f'images.shape: {str(images.shape):16}  images.dtype: {images.dtype!r}')\n",
    "  print(f'labels.keys: {labels.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index={\n",
    "    1: {\n",
    "        'id': 1,\n",
    "        'name': 'Platelets'\n",
    "       },\n",
    "    2: {\n",
    "        'id': 2,\n",
    "        'name': 'RBC'\n",
    "       },\n",
    "    3: {\n",
    "        'id': 3,\n",
    "        'name': 'WBC'\n",
    "       }\n",
    "}\n",
    "tf_ex_decoder = TfExampleDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(raw_records, num_of_examples):\n",
    "  plt.figure(figsize=(20, 20))\n",
    "  use_normalized_coordinates=True\n",
    "  min_score_thresh = 0.30\n",
    "  for i, serialized_example in enumerate(raw_records):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "    image = decoded_tensors['image'].numpy().astype('uint8')\n",
    "    scores = np.ones(shape=(len(decoded_tensors['groundtruth_boxes'])))\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image,\n",
    "        decoded_tensors['groundtruth_boxes'].numpy(),\n",
    "        decoded_tensors['groundtruth_classes'].numpy().astype('int'),\n",
    "        scores,\n",
    "        category_index=category_index,\n",
    "        use_normalized_coordinates=use_normalized_coordinates,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=min_score_thresh,\n",
    "        agnostic_mode=False,\n",
    "        instance_masks=None,\n",
    "        line_thickness=4)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image-{i+1}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 20\n",
    "num_of_examples = 3\n",
    "\n",
    "raw_records = tf.data.TFRecordDataset(\n",
    "    exp_config.task.train_data.input_path).shuffle(\n",
    "        buffer_size=buffer_size).take(num_of_examples)\n",
    "show_batch(raw_records, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_logs = core.train_lib.run_experiment(\n",
    "    distribution_strategy=distribution_strategy,\n",
    "    task=task,\n",
    "    mode='train_and_eval',\n",
    "    params=exp_config,\n",
    "    model_dir=model_dir,\n",
    "    run_post_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_saved_model_lib.export_inference_graph(\n",
    "    input_type='image_tensor',\n",
    "    batch_size=1,\n",
    "    input_image_size=[HEIGHT, WIDTH],\n",
    "    params=exp_config,\n",
    "    checkpoint_path=tf.train.latest_checkpoint(model_dir),\n",
    "    export_dir=export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  image = None\n",
    "  if(path.startswith('http')):\n",
    "    response = urlopen(path)\n",
    "    image_data = response.read()\n",
    "    image_data = BytesIO(image_data)\n",
    "    image = Image.open(image_data)\n",
    "  else:\n",
    "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(image_data))\n",
    "\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "def build_inputs_for_object_detection(image, input_image_size):\n",
    "  \"\"\"Builds Object Detection model inputs for serving.\"\"\"\n",
    "  image, _ = resize_and_crop_image(\n",
    "      image,\n",
    "      input_image_size,\n",
    "      padded_size=input_image_size,\n",
    "      aug_scale_min=1.0,\n",
    "      aug_scale_max=1.0)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_examples = 3\n",
    "\n",
    "test_ds = tf.data.TFRecordDataset(\n",
    "    './bccd_coco_tfrecords/test-00000-of-00001.tfrecord').take(\n",
    "        num_of_examples)\n",
    "show_batch(test_ds, num_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported = tf.saved_model.load(export_dir)\n",
    "model_fn = imported.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_size = (HEIGHT, WIDTH)\n",
    "plt.figure(figsize=(20, 20))\n",
    "min_score_thresh = 0.30 # Change minimum score for threshold to see all bounding boxes confidences.\n",
    "\n",
    "for i, serialized_example in enumerate(test_ds):\n",
    "  plt.subplot(1, 3, i+1)\n",
    "  decoded_tensors = tf_ex_decoder.decode(serialized_example)\n",
    "  image = build_inputs_for_object_detection(decoded_tensors['image'], input_image_size)\n",
    "  image = tf.expand_dims(image, axis=0)\n",
    "  image = tf.cast(image, dtype = tf.uint8)\n",
    "  image_np = image[0].numpy()\n",
    "  result = model_fn(image)\n",
    "  visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      result['detection_boxes'][0].numpy(),\n",
    "      result['detection_classes'][0].numpy().astype(int),\n",
    "      result['detection_scores'][0].numpy(),\n",
    "      category_index=category_index,\n",
    "      use_normalized_coordinates=False,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=min_score_thresh,\n",
    "      agnostic_mode=False,\n",
    "      instance_masks=None,\n",
    "      line_thickness=4)\n",
    "  plt.imshow(image_np)\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
